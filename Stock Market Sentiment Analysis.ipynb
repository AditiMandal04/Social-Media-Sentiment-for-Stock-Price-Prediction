{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Stock Movement Analysis Based on Social Media Sentiment**\n",
        "\n",
        "Objective:To develop a machine learning model to predict stock price movements using Reddit data."
      ],
      "metadata": {
        "id": "ImCHsfa4WVzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Scrape Data from Reddit**"
      ],
      "metadata": {
        "id": "REQKMwB5YWJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thMZYepwSvTM",
        "outputId": "dedfd248-8182-49ef-b383-9476de9bc1d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "# Create a Reddit instance\n",
        "reddit = praw.Reddit(client_id='efRoGlp-YxaeGmEED53qPw',\n",
        "                     client_secret='O4fxbrVz-HstCW8IkEhMIu2fLwt2TQ',\n",
        "                     user_agent='Aditi Mandal')\n",
        "\n",
        "# Get posts from the 'stocks' subreddit\n",
        "posts = []\n",
        "for post in reddit.subreddit('stocks').hot(limit=100):\n",
        "    posts.append([post.title, post.selftext])\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(posts, columns=['title', 'text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P62tjSRKSkTt",
        "outputId": "427355c6-eee2-4cf0-f6ed-aab1ad4968a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6RTvzTmUKuU",
        "outputId": "5d2a5887-4742-4d60-fd04-0621a146f8ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfoZ0NqYUXq2",
        "outputId": "ff9b11a8-4455-4967-9e3c-cd8fe9a6eae2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OxpkFxeUaZN",
        "outputId": "3eb94cfb-94c2-4a3a-e433-ddf9f8f4134e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.50)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Preprocessing**"
      ],
      "metadata": {
        "id": "H8wHdmJ1Y3zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine title and text for sentiment analysis\n",
        "df['content'] = df['title'] + ' ' + df['text']\n",
        "\n",
        "# Clean the data (remove NaNs, etc.)\n",
        "df.dropna(subset=['content'], inplace=True)\n"
      ],
      "metadata": {
        "id": "rUcTzv9cU53V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Perform Sentiment Analysis**"
      ],
      "metadata": {
        "id": "9AXnWEPsY788"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Sentiment Analysis using TextBlob\n",
        "df['sentiment'] = df['content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n"
      ],
      "metadata": {
        "id": "9sxxQsw_VLkc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Extract Key Features**"
      ],
      "metadata": {
        "id": "t3cMZfy8ZQ3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency of mentions\n",
        "df['mentions'] = df['content'].apply(lambda x: x.lower().count('stock'))\n",
        "\n",
        "# Save preprocessed data\n",
        "df.to_csv('preprocessed_reddit_posts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "B3pvUR6MVSZ8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Topic Modeling**"
      ],
      "metadata": {
        "id": "pzvFpaNZZdZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "def topic_modeling(data, n_topics=5):\n",
        "    vectorizer = CountVectorizer(stop_words='english')\n",
        "    dtm = vectorizer.fit_transform(data)\n",
        "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
        "    lda.fit(dtm)\n",
        "    topics = lda.transform(dtm)\n",
        "    return topics\n",
        "\n",
        "# Extract topics\n",
        "df['topics'] = list(topic_modeling(df['content']))\n"
      ],
      "metadata": {
        "id": "httmqwTKUHSu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Build the Prediction Model**"
      ],
      "metadata": {
        "id": "G7vOqoRMZoYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Example: Fetch historical stock data for a specific stock\n",
        "stock_data = yf.download('AAPL', start='2022-01-01', end='2022-12-31')\n",
        "\n",
        "# Placeholder: Merge sentiment data with stock data (additional preprocessing required)\n",
        "# Ensure date format is correct and align with stock data\n",
        "\n",
        "# Placeholder for sentiment and stock movement\n",
        "# Align this with actual stock movement data\n",
        "X = df[['sentiment', 'mentions']].values\n",
        "y = [1 if sentiment > 0 else 0 for sentiment in df['sentiment']]  # Placeholder target variable\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd9R5IZyVjy9",
        "outputId": "bb50e806-770a-4889-dc2b-7159f9b3cd38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import re\n",
        "\n",
        "# Reddit Data Processing\n",
        "reddit = praw.Reddit(client_id='EwEvkfwnUKAcj3JpPKqnQQ',\n",
        "                     client_secret='sweGCesqoOuZB-93LpUYOWv1ssprjw',\n",
        "                     user_agent='Hrsht')\n",
        "\n",
        "posts = []\n",
        "for post in reddit.subreddit('stocks').hot(limit=100):\n",
        "    posts.append([post.title, post.selftext])\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(posts, columns=['title', 'text'])\n",
        "df['content'] = df['title'] + ' ' + df['text']\n",
        "df.dropna(subset=['content'], inplace=True)\n",
        "\n",
        "# Sentiment Analysis\n",
        "df['sentiment'] = df['content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "df['mentions'] = df['content'].apply(lambda x: x.lower().count('stock'))\n",
        "\n",
        "# Extract Date from Content (if present) or use Scrape Date\n",
        "def extract_date(text):\n",
        "    try:\n",
        "        # Regex to match YYYY-MM-DD\n",
        "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\n",
        "        if match:\n",
        "            return pd.to_datetime(match.group(), format='%Y-%m-%d')\n",
        "    except Exception:\n",
        "        pass\n",
        "    return pd.NaT  # Return NaT (Not a Time) if no date found\n",
        "\n",
        "df['date'] = df['content'].apply(extract_date)\n",
        "df['date'].fillna(pd.Timestamp.now().normalize(), inplace=True)\n",
        "\n",
        "# Stock Data Processing\n",
        "stock_data = yf.download('AAPL', start='2022-01-01', end='2022-12-31')\n",
        "stock_data['daily_return'] = stock_data['Adj Close'].pct_change()\n",
        "stock_data['10d_ma'] = stock_data['Adj Close'].rolling(window=10).mean()\n",
        "stock_data['50d_ma'] = stock_data['Adj Close'].rolling(window=50).mean()\n",
        "stock_data['movement'] = np.where(stock_data['daily_return'] > 0, 1, 0)  # Upward movement = 1, else 0\n",
        "\n",
        "# Reset index for stock data to avoid level mismatch\n",
        "stock_data.reset_index(inplace=True)\n",
        "\n",
        "# Align sentiment data with stock data\n",
        "try:\n",
        "    # Ensure both DataFrames have compatible structures\n",
        "    print(stock_data.head())  # Debug: Check stock_data structure\n",
        "    print(df.head())  # Debug: Check df structure\n",
        "\n",
        "    if 'Date' in stock_data.columns and 'date' in df.columns:\n",
        "        # Reset MultiIndex in stock_data if it exists\n",
        "        stock_data.reset_index(inplace=True)\n",
        "\n",
        "        # Ensure 'Date' in stock_data is a datetime object\n",
        "        stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
        "\n",
        "        # Ensure 'date' in df is also a datetime object\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "        # Merge DataFrames\n",
        "        merged_data = pd.merge(stock_data, df, left_on='Date', right_on='date', how='inner')\n",
        "\n",
        "        if merged_data.empty:\n",
        "            raise ValueError(\"Merged DataFrame is empty. Check if 'Date' and 'date' columns align.\")\n",
        "    else:\n",
        "        raise ValueError(\"Missing 'Date' or 'date' columns in the dataframes.\")\n",
        "except ValueError as e:\n",
        "    print(f\"MergeError: {e}\")\n",
        "    print(\"Ensure both dataframes have compatible index or column structure before merging.\")\n",
        "    merged_data = None  # Prevent further execution if merge fails\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvJtlhTrV1NW",
        "outputId": "5591b3c4-61d2-43ca-8bba-fdc4c829b8c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "<ipython-input-13-49304c2801be>:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['date'].fillna(pd.Timestamp.now().normalize(), inplace=True)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Date   Adj Close       Close        High         Low        Open  \\\n",
            "Ticker                   AAPL        AAPL        AAPL        AAPL        AAPL   \n",
            "0      2022-01-03  179.076614  182.009995  182.880005  177.710007  177.830002   \n",
            "1      2022-01-04  176.803802  179.699997  182.940002  179.119995  182.630005   \n",
            "2      2022-01-05  172.100830  174.919998  180.169998  174.639999  179.610001   \n",
            "3      2022-01-06  169.227936  172.000000  175.300003  171.639999  172.699997   \n",
            "4      2022-01-07  169.395187  172.169998  174.139999  171.029999  172.889999   \n",
            "\n",
            "Price      Volume daily_return 10d_ma 50d_ma movement  \n",
            "Ticker       AAPL                                      \n",
            "0       104487900          NaN    NaN    NaN        0  \n",
            "1        99310400    -0.012692    NaN    NaN        0  \n",
            "2        94537600    -0.026600    NaN    NaN        0  \n",
            "3        96904000    -0.016693    NaN    NaN        0  \n",
            "4        86709100     0.000988    NaN    NaN        1  \n",
            "                                               title  \\\n",
            "0  Rate My Portfolio - r/Stocks Quarterly Thread ...   \n",
            "1  r/Stocks Daily Discussion & Fundamentals Frida...   \n",
            "2                          $PLTR where is the value?   \n",
            "3  November's job report shows that nonfarm payro...   \n",
            "4  Gelsinger's push into software and edge comput...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Please use this thread to discuss your portfol...   \n",
            "1  This is the daily discussion, so anything stoc...   \n",
            "2  For anyone putting in buy orders at this level...   \n",
            "3  Total nonfarm payroll employment rose by 227,0...   \n",
            "4  Intel was making some interesting moves into s...   \n",
            "\n",
            "                                             content  sentiment  mentions  \\\n",
            "0  Rate My Portfolio - r/Stocks Quarterly Thread ...   0.186026        10   \n",
            "1  r/Stocks Daily Discussion & Fundamentals Frida...   0.035218        14   \n",
            "2  $PLTR where is the value? For anyone putting i...   0.035714         0   \n",
            "3  November's job report shows that nonfarm payro...  -0.026157         0   \n",
            "4  Gelsinger's push into software and edge comput...   0.182407         1   \n",
            "\n",
            "        date  \n",
            "0 2024-12-06  \n",
            "1 2024-12-06  \n",
            "2 2024-12-06  \n",
            "3 2024-12-06  \n",
            "4 2024-12-06  \n",
            "MergeError: Not allowed to merge between different levels. (2 levels on the left, 1 on the right)\n",
            "Ensure both dataframes have compatible index or column structure before merging.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}